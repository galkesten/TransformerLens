{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa05580-5cab-4b40-90bf-3234c3c34b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "176ac421-cfdf-47b5-a88f-39b22dcc337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import torch\n",
    "from jaxtyping import Float\n",
    "from torch.testing import assert_close\n",
    "import torch.nn as nn\n",
    "from transformer_lens.components import Attention\n",
    "from transformer_lens.components import LayerNorm\n",
    "from esm.layers.attention import MultiHeadAttention\n",
    "from transformer_lens.HookedTransformerConfig import HookedTransformerConfig\n",
    "import functools\n",
    "import einops\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "384605f0-1c01-4a45-8388-d66210b619dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOL = 1e-4\n",
    "def create_multi_head_attention_params(d_model, n_heads, bias=False, qk_layernorm=False):\n",
    "    params = {\n",
    "        \"layernorm_qkv_weight\": torch.rand(d_model),  # Weight of LayerNorm\n",
    "        \"layernorm_qkv_bias\": torch.rand(d_model) if bias else None,    # Bias of LayerNorm\n",
    "        \"W_qkv_weight\": torch.rand(d_model * 3, d_model),  # Weight of Linear layer\n",
    "        \"W_qkv_bias\": torch.rand(d_model * 3) if bias else None,  # Bias of Linear layer\n",
    "        \"out_proj_weight\": torch.rand(d_model, d_model),  # Output projection weight\n",
    "        \"out_proj_bias\": torch.rand(d_model) if bias else None,  # Output projection bias\n",
    "    }\n",
    "    \n",
    "    if qk_layernorm:\n",
    "        params.update({\n",
    "            \"q_ln_weight\": torch.rand(d_model),\n",
    "            \"q_ln_bias\": torch.rand(d_model) if bias else None,\n",
    "            \"k_ln_weight\": torch.rand(d_model),\n",
    "            \"k_ln_bias\": torch.rand(d_model) if bias else None,\n",
    "        })\n",
    "    return params\n",
    "    \n",
    "\n",
    "def assign_params_to__esm_attention_layer(layer, params, bias=True):\n",
    "    with torch.no_grad():\n",
    "        # Assign LayerNorm for QKV\n",
    "        layer.layernorm_qkv[0].weight.copy_(params[\"layernorm_qkv_weight\"])\n",
    "        if bias:\n",
    "            layer.layernorm_qkv[0].bias.copy_(params[\"layernorm_qkv_bias\"])\n",
    "        \n",
    "        # Assign Weights and Bias for QKV Projection\n",
    "        layer.layernorm_qkv[1].weight.copy_(params[\"W_qkv_weight\"])\n",
    "        if bias:\n",
    "            layer.layernorm_qkv[1].bias.copy_(params[\"W_qkv_bias\"])\n",
    "        \n",
    "        # Assign Output Projection\n",
    "        layer.out_proj.weight.copy_(params[\"out_proj_weight\"])\n",
    "        if bias:\n",
    "            layer.out_proj.bias.copy_(params[\"out_proj_bias\"])\n",
    "        \n",
    "        # Assign LayerNorm for Q\n",
    "        if isinstance(layer.q_ln, nn.LayerNorm):\n",
    "            layer.q_ln.weight.copy_(params[\"q_ln_weight\"])\n",
    "            if bias:\n",
    "                layer.q_ln.bias.copy_(params[\"q_ln_bias\"])\n",
    "        \n",
    "        # Assign LayerNorm for K\n",
    "        if isinstance(layer.k_ln, nn.LayerNorm):\n",
    "            layer.k_ln.weight.copy_(params[\"k_ln_weight\"])\n",
    "            if bias:\n",
    "                layer.k_ln.bias.copy_(params[\"k_ln_bias\"])\n",
    "\n",
    "def assign_params_to_transformer_lens_attention_layer(attention_layer, pre_layer_norm, params, cfg, bias=True):\n",
    "    with torch.no_grad():\n",
    "        # Assign LayerNorm QKV\n",
    "        pre_layer_norm.w.copy_(params[\"layernorm_qkv_weight\"])\n",
    "        if bias and \"layernorm_qkv_bias\" in params:\n",
    "            pre_layer_norm.b.copy_(params[\"layernorm_qkv_bias\"])\n",
    "\n",
    "        # Extract and split QKV weights\n",
    "        qkv_matrix = params[\"W_qkv_weight\"].clone()  # Shape: (d_model * 3, d_model)\n",
    "        assert qkv_matrix.shape == (cfg.d_model * 3, cfg.d_model), \"QKV weight shape mismatch.\"\n",
    "\n",
    "        qkv_reshaped = qkv_matrix.T  # Shape: (d_model, d_model * 3)\n",
    "        q, k, v = torch.chunk(qkv_reshaped, 3, dim=-1)  # Split into Q, K, V\n",
    "        \n",
    "        reshaper = functools.partial(\n",
    "            einops.rearrange, pattern=\"d_model (n_head d_head) -> n_head d_model d_head\", n_head=cfg.n_heads\n",
    "        )\n",
    "        q, k, v = map(reshaper, (q, k, v))\n",
    "        \n",
    "        # Copy Q, K, V weights\n",
    "        attention_layer.W_Q.copy_(q)\n",
    "        attention_layer.W_K.copy_(k)\n",
    "        attention_layer.W_V.copy_(v)\n",
    "\n",
    "        # Handle QKV bias\n",
    "        if bias and \"W_qkv_bias\" in params:\n",
    "            qkv_bias = params[\"W_qkv_bias\"].clone()  # Shape: (d_model * 3)\n",
    "            b_q, b_k, b_v = torch.chunk(qkv_bias, 3, dim=-1)\n",
    "            reshaper_bias = functools.partial(\n",
    "                einops.rearrange, pattern=\"(n_head d_head) -> n_head d_head\", n_head=cfg.n_heads\n",
    "            )\n",
    "            attention_layer.b_Q.copy_(reshaper_bias(b_q))\n",
    "            attention_layer.b_K.copy_(reshaper_bias(b_k))\n",
    "            attention_layer.b_V.copy_(reshaper_bias(b_v))\n",
    "\n",
    "        # Assign Output Projection\n",
    "        out_proj = params[\"out_proj_weight\"].clone()  # Shape: (d_model, d_model)\n",
    "        assert out_proj.shape == (cfg.d_model, cfg.d_model), \"Output projection weight shape mismatch.\"\n",
    "        out_proj_reshaped = einops.rearrange(out_proj.T, \"(n_head d_head) d_model -> n_head d_head d_model\", n_head=cfg.n_heads)\n",
    "        attention_layer.W_O.copy_(out_proj_reshaped)\n",
    "\n",
    "        # Assign Output Bias\n",
    "        if bias and \"out_proj_bias\" in params:\n",
    "            attention_layer.b_O.copy_(params[\"out_proj_bias\"])\n",
    "\n",
    "        # Assign LayerNorms for Q and K if qk_layernorm is enabled\n",
    "        if cfg.qk_layernorm:\n",
    "            attention_layer.q_ln.w.copy_(params[\"q_ln_weight\"])\n",
    "            attention_layer.k_ln.w.copy_(params[\"k_ln_weight\"])\n",
    "            if bias:\n",
    "                attention_layer.q_ln.b.copy_(params.get(\"q_ln_bias\", torch.zeros(cfg.d_model)))\n",
    "                attention_layer.k_ln.b.copy_(params.get(\"k_ln_bias\", torch.zeros(cfg.d_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0aaa8cd-cb92-4f22-bb77-6cac322472fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "n_heads = 8\n",
    "d_head = d_model // n_heads\n",
    "bias = False\n",
    "batch_size = 10\n",
    "seq_len = 10\n",
    "qk_layernorm= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d1961a8e-1eaa-4b60-8326-dc55781f4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_params = create_multi_head_attention_params(d_model, n_heads, bias=bias, qk_layernorm=qk_layernorm)\n",
    "\n",
    "# Create ESM original attention component\n",
    "esm_original_component = MultiHeadAttention(d_model, n_heads, bias, qk_layernorm).to(torch.float32)\n",
    "\n",
    "# Assign the explicit parameters to the model\n",
    "assign_params_to__esm_attention_layer(esm_original_component, fake_params, bias)\n",
    "\n",
    "#Now we want to create attention of transformer lens for comparing...\n",
    "\n",
    "cfg = HookedTransformerConfig(\n",
    "n_layers=1,           \n",
    "d_model=d_model,           \n",
    "n_ctx=20,            \n",
    "d_head=d_head,                     \n",
    "n_heads=n_heads,\n",
    "attention_dir=\"bidirectional\",\n",
    "init_weights=False,\n",
    "positional_embedding_type=\"rotary\",\n",
    "rotary_dim=d_head,\n",
    "default_prepend_bos=False,\n",
    "qk_layernorm=qk_layernorm,\n",
    "dtype=torch.float32,\n",
    "attn_only=True,\n",
    "use_attn_result=False\n",
    ")\n",
    "\n",
    "#create transformer lens attention and initialize: \n",
    "tested_attention_layer = Attention(cfg)\n",
    "pre_layer_norm = LayerNorm(cfg, d_model)\n",
    "assign_params_to_transformer_lens_attention_layer(tested_attention_layer, pre_layer_norm,fake_params, cfg, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c0af246-3398-436b-b80a-2784a2d20ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "torch.Size([10, 8, 10, 64])\n",
      "tensor([[[ 3.0243e+02,  2.9030e+02,  3.1657e+02,  ...,  3.1700e+02,\n",
      "           3.0445e+02,  2.9163e+02],\n",
      "         [ 3.3427e+02,  3.2994e+02,  3.4836e+02,  ...,  3.5302e+02,\n",
      "           3.3805e+02,  3.2873e+02],\n",
      "         [ 3.8418e+02,  3.8537e+02,  4.1591e+02,  ...,  4.0084e+02,\n",
      "           4.0166e+02,  3.8421e+02],\n",
      "         ...,\n",
      "         [ 2.9701e+02,  2.8587e+02,  3.0819e+02,  ...,  3.1114e+02,\n",
      "           3.0583e+02,  2.8690e+02],\n",
      "         [ 3.1077e+02,  3.0824e+02,  3.3486e+02,  ...,  3.3666e+02,\n",
      "           3.2267e+02,  3.0997e+02],\n",
      "         [ 3.3301e+02,  3.2017e+02,  3.5319e+02,  ...,  3.5345e+02,\n",
      "           3.3967e+02,  3.2283e+02]],\n",
      "\n",
      "        [[-1.0949e+02, -1.1138e+02, -1.2704e+02,  ..., -1.1981e+02,\n",
      "          -1.1537e+02, -1.1542e+02],\n",
      "         [-1.0969e+02, -1.0966e+02, -1.2139e+02,  ..., -1.1902e+02,\n",
      "          -1.1746e+02, -1.1306e+02],\n",
      "         [-9.4633e+01, -9.6794e+01, -1.1104e+02,  ..., -1.0608e+02,\n",
      "          -1.0997e+02, -1.0186e+02],\n",
      "         ...,\n",
      "         [-5.4705e+01, -6.0719e+01, -5.9618e+01,  ..., -5.9506e+01,\n",
      "          -6.0216e+01, -5.6162e+01],\n",
      "         [-1.1995e+02, -1.2259e+02, -1.3115e+02,  ..., -1.2671e+02,\n",
      "          -1.2809e+02, -1.1718e+02],\n",
      "         [-8.4885e+01, -8.6357e+01, -9.5990e+01,  ..., -9.9894e+01,\n",
      "          -9.8749e+01, -8.3071e+01]],\n",
      "\n",
      "        [[-1.2976e+01, -1.4460e+01,  2.0136e+00,  ..., -1.6355e+01,\n",
      "          -7.8422e+00, -8.9905e+00],\n",
      "         [-3.2497e+01, -3.6182e+01, -2.3284e+01,  ..., -3.3919e+01,\n",
      "          -2.6324e+01, -3.3086e+01],\n",
      "         [ 1.5248e+01,  1.4174e+01,  2.9814e+01,  ...,  1.7277e+01,\n",
      "           1.9194e+01,  1.2902e+01],\n",
      "         ...,\n",
      "         [-7.5414e+00, -1.5513e+01,  4.3059e+00,  ..., -1.0703e+01,\n",
      "          -6.0475e+00, -9.9884e+00],\n",
      "         [-1.3988e+00, -2.0014e+00,  5.6679e+00,  ..., -6.7519e+00,\n",
      "          -4.4068e+00, -6.4943e+00],\n",
      "         [ 2.1724e+00,  3.7680e+00,  1.7966e+01,  ...,  3.7176e+00,\n",
      "           1.1191e+01, -3.4773e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.0275e+01,  9.3327e+01,  9.4884e+01,  ...,  8.5287e+01,\n",
      "           9.4470e+01,  9.6798e+01],\n",
      "         [ 8.9058e+01,  1.1034e+02,  1.0378e+02,  ...,  9.6572e+01,\n",
      "           1.0662e+02,  1.0087e+02],\n",
      "         [ 4.3943e+01,  5.7258e+01,  4.9041e+01,  ...,  4.5950e+01,\n",
      "           6.1709e+01,  5.1613e+01],\n",
      "         ...,\n",
      "         [ 7.8299e+01,  8.9999e+01,  9.4163e+01,  ...,  8.7065e+01,\n",
      "           9.9968e+01,  9.3201e+01],\n",
      "         [ 8.7362e+01,  8.5529e+01,  8.3321e+01,  ...,  8.0745e+01,\n",
      "           1.0171e+02,  9.1886e+01],\n",
      "         [ 6.8454e+01,  7.7930e+01,  6.9559e+01,  ...,  6.8009e+01,\n",
      "           8.1871e+01,  7.6011e+01]],\n",
      "\n",
      "        [[-1.7579e+02, -1.9951e+02, -1.9495e+02,  ..., -1.8614e+02,\n",
      "          -2.0587e+02, -1.9329e+02],\n",
      "         [-1.6812e+02, -1.9111e+02, -1.7675e+02,  ..., -1.7058e+02,\n",
      "          -1.8995e+02, -1.7359e+02],\n",
      "         [-1.8196e+02, -1.9708e+02, -1.8628e+02,  ..., -1.7876e+02,\n",
      "          -2.0589e+02, -1.9030e+02],\n",
      "         ...,\n",
      "         [-1.7050e+02, -1.9000e+02, -1.8114e+02,  ..., -1.7710e+02,\n",
      "          -1.9640e+02, -1.7938e+02],\n",
      "         [-2.0201e+02, -2.3297e+02, -2.1973e+02,  ..., -2.1457e+02,\n",
      "          -2.2946e+02, -2.1732e+02],\n",
      "         [-2.0411e+02, -2.2071e+02, -2.1389e+02,  ..., -2.0590e+02,\n",
      "          -2.3127e+02, -2.1630e+02]],\n",
      "\n",
      "        [[-6.6588e+02, -6.4074e+02, -6.7935e+02,  ..., -6.7631e+02,\n",
      "          -6.5278e+02, -6.6225e+02],\n",
      "         [-6.6929e+02, -6.3525e+02, -6.7938e+02,  ..., -6.7919e+02,\n",
      "          -6.5098e+02, -6.6665e+02],\n",
      "         [-7.0993e+02, -6.9326e+02, -7.2878e+02,  ..., -7.2414e+02,\n",
      "          -6.9685e+02, -7.1694e+02],\n",
      "         ...,\n",
      "         [-7.0411e+02, -6.8038e+02, -7.2525e+02,  ..., -7.1586e+02,\n",
      "          -6.9124e+02, -7.1015e+02],\n",
      "         [-6.6936e+02, -6.5188e+02, -6.8401e+02,  ..., -6.8131e+02,\n",
      "          -6.5648e+02, -6.7133e+02],\n",
      "         [-6.9648e+02, -6.6369e+02, -7.1419e+02,  ..., -7.1151e+02,\n",
      "          -6.9015e+02, -6.9280e+02]]])\n"
     ]
    }
   ],
   "source": [
    "x= torch.rand((batch_size, seq_len, d_model))\n",
    "with torch.no_grad():\n",
    "    layer_norm1= pre_layer_norm(x.clone())\n",
    "    q1, k1, v1 = tested_attention_layer.calculate_qkv_matrices(layer_norm1, layer_norm1, layer_norm1)\n",
    "    q1_flattened = einops.rearrange(q1, \"batch pos head_index d_head -> batch pos (head_index d_head)\")\n",
    "    k1_flattened = einops.rearrange(k1, \"batch pos head_index d_head -> batch pos (head_index d_head)\")\n",
    "    v1_flattened = einops.rearrange(v1, \"batch pos head_index d_head -> batch pos (head_index d_head)\")\n",
    "    if cfg.qk_layernorm:\n",
    "        q1 = tested_attention_layer.q_ln(q1_flattened)\n",
    "        k1 = tested_attention_layer.k_ln(k1_flattened)\n",
    "        q1 = einops.rearrange(q1, \"batch pos (head_index d_head) -> batch pos head_index d_head\", \n",
    "                                    head_index=cfg.n_heads, d_head=cfg.d_head)\n",
    "        k1 = einops.rearrange(k1, \"batch kv_pos (head_index d_head) -> batch kv_pos head_index d_head\", \n",
    "                        head_index=cfg.n_heads, d_head=cfg.d_head)\n",
    "    if cfg.positional_embedding_type == \"rotary\":\n",
    "        print(\"enter\")\n",
    "        kv_cache_pos_offset = 0\n",
    "        q1 = tested_attention_layer.apply_rotary(q1, kv_cache_pos_offset, None)\n",
    "        k1 = tested_attention_layer.apply_rotary(k1, 0, None)\n",
    "    q1 = einops.rearrange(q1, \"batch pos head_index d_head -> batch head_index pos d_head\")\n",
    "    k1 = einops.rearrange(k1, \"batch pos head_index d_head -> batch head_index pos d_head\")\n",
    "    v1 = einops.rearrange(v1, \"batch pos head_index d_head -> batch head_index pos d_head\")\n",
    "    # attn_scores = tested_attention_layer.calculate_attention_scores(q1, k1) \n",
    "    # pattern = F.softmax(attn_scores, dim=-1)\n",
    "    # pattern = torch.where(torch.isnan(pattern), torch.zeros_like(pattern), pattern)\n",
    "    # pattern = pattern.to(tested_attention_layer.cfg.dtype)\n",
    "    # pattern = pattern.to(v1.device)\n",
    "    # z = tested_attention_layer.calculate_z_scores(v1, pattern)  # [batch, pos, head_index, d_head]\n",
    "    z= F.scaled_dot_product_attention(\n",
    "                    q1, k1, v1\n",
    "                )\n",
    "    if not tested_attention_layer.cfg.use_attn_result:\n",
    "        w = einops.rearrange(\n",
    "            tested_attention_layer.W_O, \"head_index d_head d_model -> d_model (head_index d_head)\"\n",
    "        )\n",
    "        print(z.shape)\n",
    "        # ctx1=z.reshape(z.shape[0], z.shape[1], tested_attention_layer.cfg.d_head * tested_attention_layer.cfg.n_heads)\n",
    "        ctx1 = einops.rearrange(z, \"b h s d -> b s (h d)\")\n",
    "        out1 = F.linear(\n",
    "           ctx1,\n",
    "            w,\n",
    "            tested_attention_layer.b_O,\n",
    "        )\n",
    "        print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b10788b0-c397-4d6b-8e43-d2df72e6deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.0243e+02,  2.9030e+02,  3.1657e+02,  ...,  3.1700e+02,\n",
      "           3.0445e+02,  2.9163e+02],\n",
      "         [ 3.3427e+02,  3.2994e+02,  3.4836e+02,  ...,  3.5302e+02,\n",
      "           3.3804e+02,  3.2872e+02],\n",
      "         [ 3.8418e+02,  3.8536e+02,  4.1591e+02,  ...,  4.0084e+02,\n",
      "           4.0166e+02,  3.8421e+02],\n",
      "         ...,\n",
      "         [ 2.9701e+02,  2.8587e+02,  3.0819e+02,  ...,  3.1114e+02,\n",
      "           3.0583e+02,  2.8690e+02],\n",
      "         [ 3.1077e+02,  3.0823e+02,  3.3485e+02,  ...,  3.3666e+02,\n",
      "           3.2267e+02,  3.0997e+02],\n",
      "         [ 3.3301e+02,  3.2016e+02,  3.5319e+02,  ...,  3.5345e+02,\n",
      "           3.3967e+02,  3.2283e+02]],\n",
      "\n",
      "        [[-1.0948e+02, -1.1138e+02, -1.2704e+02,  ..., -1.1981e+02,\n",
      "          -1.1537e+02, -1.1542e+02],\n",
      "         [-1.0969e+02, -1.0966e+02, -1.2139e+02,  ..., -1.1902e+02,\n",
      "          -1.1746e+02, -1.1306e+02],\n",
      "         [-9.4632e+01, -9.6793e+01, -1.1104e+02,  ..., -1.0608e+02,\n",
      "          -1.0997e+02, -1.0186e+02],\n",
      "         ...,\n",
      "         [-5.4704e+01, -6.0718e+01, -5.9617e+01,  ..., -5.9506e+01,\n",
      "          -6.0216e+01, -5.6161e+01],\n",
      "         [-1.1995e+02, -1.2259e+02, -1.3115e+02,  ..., -1.2671e+02,\n",
      "          -1.2809e+02, -1.1718e+02],\n",
      "         [-8.4885e+01, -8.6356e+01, -9.5990e+01,  ..., -9.9894e+01,\n",
      "          -9.8748e+01, -8.3070e+01]],\n",
      "\n",
      "        [[-1.2975e+01, -1.4460e+01,  2.0141e+00,  ..., -1.6355e+01,\n",
      "          -7.8416e+00, -8.9900e+00],\n",
      "         [-3.2497e+01, -3.6181e+01, -2.3283e+01,  ..., -3.3919e+01,\n",
      "          -2.6324e+01, -3.3086e+01],\n",
      "         [ 1.5249e+01,  1.4174e+01,  2.9814e+01,  ...,  1.7278e+01,\n",
      "           1.9194e+01,  1.2902e+01],\n",
      "         ...,\n",
      "         [-7.5411e+00, -1.5513e+01,  4.3062e+00,  ..., -1.0703e+01,\n",
      "          -6.0472e+00, -9.9880e+00],\n",
      "         [-1.3984e+00, -2.0011e+00,  5.6683e+00,  ..., -6.7516e+00,\n",
      "          -4.4064e+00, -6.4940e+00],\n",
      "         [ 2.1729e+00,  3.7686e+00,  1.7967e+01,  ...,  3.7182e+00,\n",
      "           1.1192e+01, -3.4714e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.0275e+01,  9.3327e+01,  9.4884e+01,  ...,  8.5287e+01,\n",
      "           9.4470e+01,  9.6799e+01],\n",
      "         [ 8.9058e+01,  1.1034e+02,  1.0378e+02,  ...,  9.6572e+01,\n",
      "           1.0662e+02,  1.0087e+02],\n",
      "         [ 4.3943e+01,  5.7259e+01,  4.9042e+01,  ...,  4.5950e+01,\n",
      "           6.1709e+01,  5.1613e+01],\n",
      "         ...,\n",
      "         [ 7.8299e+01,  8.9999e+01,  9.4163e+01,  ...,  8.7065e+01,\n",
      "           9.9968e+01,  9.3201e+01],\n",
      "         [ 8.7362e+01,  8.5530e+01,  8.3321e+01,  ...,  8.0745e+01,\n",
      "           1.0171e+02,  9.1887e+01],\n",
      "         [ 6.8454e+01,  7.7930e+01,  6.9560e+01,  ...,  6.8009e+01,\n",
      "           8.1871e+01,  7.6011e+01]],\n",
      "\n",
      "        [[-1.7579e+02, -1.9950e+02, -1.9495e+02,  ..., -1.8614e+02,\n",
      "          -2.0587e+02, -1.9329e+02],\n",
      "         [-1.6812e+02, -1.9111e+02, -1.7675e+02,  ..., -1.7057e+02,\n",
      "          -1.8995e+02, -1.7358e+02],\n",
      "         [-1.8196e+02, -1.9708e+02, -1.8628e+02,  ..., -1.7876e+02,\n",
      "          -2.0589e+02, -1.9030e+02],\n",
      "         ...,\n",
      "         [-1.7049e+02, -1.9000e+02, -1.8113e+02,  ..., -1.7710e+02,\n",
      "          -1.9640e+02, -1.7938e+02],\n",
      "         [-2.0201e+02, -2.3297e+02, -2.1973e+02,  ..., -2.1457e+02,\n",
      "          -2.2945e+02, -2.1732e+02],\n",
      "         [-2.0411e+02, -2.2071e+02, -2.1389e+02,  ..., -2.0590e+02,\n",
      "          -2.3127e+02, -2.1630e+02]],\n",
      "\n",
      "        [[-6.6589e+02, -6.4074e+02, -6.7936e+02,  ..., -6.7632e+02,\n",
      "          -6.5278e+02, -6.6225e+02],\n",
      "         [-6.6929e+02, -6.3525e+02, -6.7938e+02,  ..., -6.7919e+02,\n",
      "          -6.5099e+02, -6.6665e+02],\n",
      "         [-7.0993e+02, -6.9326e+02, -7.2878e+02,  ..., -7.2414e+02,\n",
      "          -6.9686e+02, -7.1694e+02],\n",
      "         ...,\n",
      "         [-7.0412e+02, -6.8038e+02, -7.2526e+02,  ..., -7.1586e+02,\n",
      "          -6.9124e+02, -7.1015e+02],\n",
      "         [-6.6937e+02, -6.5188e+02, -6.8401e+02,  ..., -6.8131e+02,\n",
      "          -6.5648e+02, -6.7133e+02],\n",
      "         [-6.9648e+02, -6.6370e+02, -7.1420e+02,  ..., -7.1151e+02,\n",
      "          -6.9015e+02, -6.9280e+02]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    qkv=esm_original_component.layernorm_qkv(x.clone())\n",
    "    q2, k2, v2 = torch.chunk(qkv, 3, dim=-1)\n",
    "    q2,k2 = (\n",
    "                esm_original_component.q_ln(q2).to(q2.dtype),\n",
    "                esm_original_component.k_ln(k2).to(q2.dtype),\n",
    "            )\n",
    "    q2, k2 = esm_original_component._apply_rotary(q2, k2)\n",
    "    n_heads = esm_original_component.n_heads\n",
    "    reshaper = functools.partial(\n",
    "        einops.rearrange, pattern=\"b s (h d) -> b h s d\", h=n_heads\n",
    "    )\n",
    "    q2, k2, v2 = map(\n",
    "        reshaper, (q2, k2, v2)\n",
    "    )\n",
    "    \n",
    "    ctx2 = F.scaled_dot_product_attention(\n",
    "        q2, k2, v2\n",
    "    )\n",
    "    ctx2 = einops.rearrange(ctx2, \"b h s d -> b s (h d)\")\n",
    "    out2=esm_original_component.out_proj(ctx2)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2a8014d2-6413-4d48-b578-62b040201648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#print(torch.allclose(q1, q2, atol=ATOL))\n",
    "#print(torch.allclose(k1, k2, atol=ATOL))\n",
    "#print(torch.allclose(v1_flattened, v2, atol=ATOL))\n",
    "print(torch.allclose(ctx1,ctx2, atol=ATOL))\n",
    "print(torch.allclose(w, esm_original_component.out_proj.weight, atol=ATOL))\n",
    "print(torch.allclose(out1, out2, atol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f02e6448-c619-4920-a4c6-7346c8980855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(torch.zeros(10), torch.zeros(10), atol=ATOL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49e1f225-23da-41e3-8759-4c6c10b5650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.rand((batch_size, seq_len, d_model))\n",
    "\n",
    "layer_norm1= pre_layer_norm(x.clone())\n",
    "res1=tested_attention_layer.forward(layer_norm1,layer_norm1,layer_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "485ee97f-14be-4d4f-b013-5edb9a87a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_id = torch.tensor([[1,1,1,1,0,0,0,0,0,0]])\n",
    "seq_id = None\n",
    "res2=esm_original_component.forward(x,seq_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dcf9e715-32e0-46cc-958f-dde6684edd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.6625e+01,  1.0004e+02,  8.5801e+01,  ...,  8.7451e+01,\n",
       "           9.1848e+01,  7.8041e+01],\n",
       "         [ 8.8997e+01,  1.0819e+02,  9.4817e+01,  ...,  8.4767e+01,\n",
       "           9.4909e+01,  7.5189e+01],\n",
       "         [ 3.7773e+01,  5.9993e+01,  3.8074e+01,  ...,  3.0051e+01,\n",
       "           4.2727e+01,  3.2113e+01],\n",
       "         ...,\n",
       "         [ 7.2632e+01,  8.7934e+01,  6.9827e+01,  ...,  6.4970e+01,\n",
       "           7.3000e+01,  6.3227e+01],\n",
       "         [ 1.4556e+01,  3.9058e+01,  2.0168e+01,  ...,  1.6914e-01,\n",
       "           2.0829e+01,  1.2688e+01],\n",
       "         [ 7.2108e+01,  8.9306e+01,  7.1060e+01,  ...,  6.4950e+01,\n",
       "           9.0310e+01,  5.9327e+01]],\n",
       "\n",
       "        [[ 6.7271e+01,  8.0738e+01,  9.4497e+01,  ...,  7.3725e+01,\n",
       "           7.8386e+01,  9.5042e+01],\n",
       "         [ 4.2411e+01,  5.2446e+01,  5.8948e+01,  ...,  3.9208e+01,\n",
       "           4.4769e+01,  6.2315e+01],\n",
       "         [ 2.5081e+01,  3.2241e+01,  3.6895e+01,  ...,  1.4308e+01,\n",
       "           2.8353e+01,  4.3983e+01],\n",
       "         ...,\n",
       "         [ 2.0624e+01,  2.8158e+01,  3.3531e+01,  ...,  8.4391e+00,\n",
       "           2.1195e+01,  3.3178e+01],\n",
       "         [ 1.9107e+01,  2.2767e+01,  3.1753e+01,  ...,  9.7106e+00,\n",
       "           1.8239e+01,  3.8132e+01],\n",
       "         [ 5.5312e+01,  6.3665e+01,  8.3025e+01,  ...,  5.0454e+01,\n",
       "           7.0360e+01,  8.3968e+01]],\n",
       "\n",
       "        [[-9.2828e+01, -8.9144e+01, -9.3193e+01,  ..., -8.0003e+01,\n",
       "          -8.4481e+01, -7.4275e+01],\n",
       "         [-8.5120e+00, -8.5242e+00, -2.1452e+01,  ...,  4.2071e+00,\n",
       "          -8.8899e+00,  1.0018e+00],\n",
       "         [-1.4441e+02, -1.3510e+02, -1.5305e+02,  ..., -1.2592e+02,\n",
       "          -1.4474e+02, -1.3103e+02],\n",
       "         ...,\n",
       "         [-2.5822e+01, -2.5320e+01, -3.1543e+01,  ..., -3.3269e+00,\n",
       "          -2.2885e+01, -1.4478e+01],\n",
       "         [-8.3255e+01, -7.5704e+01, -8.9342e+01,  ..., -6.2693e+01,\n",
       "          -8.0315e+01, -6.9162e+01],\n",
       "         [-9.2838e+01, -8.6358e+01, -9.4982e+01,  ..., -7.3363e+01,\n",
       "          -8.4195e+01, -7.7698e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.3327e+02, -2.3048e+02, -2.6054e+02,  ..., -2.3539e+02,\n",
       "          -2.3759e+02, -2.4009e+02],\n",
       "         [-1.6389e+02, -1.6570e+02, -1.8834e+02,  ..., -1.7098e+02,\n",
       "          -1.7373e+02, -1.7032e+02],\n",
       "         [-2.0600e+02, -2.1023e+02, -2.3443e+02,  ..., -2.0950e+02,\n",
       "          -2.1448e+02, -2.1053e+02],\n",
       "         ...,\n",
       "         [-1.7779e+02, -1.8613e+02, -2.0645e+02,  ..., -1.8145e+02,\n",
       "          -1.8151e+02, -1.8942e+02],\n",
       "         [-1.7774e+02, -1.7523e+02, -2.0816e+02,  ..., -1.8391e+02,\n",
       "          -1.8146e+02, -1.8661e+02],\n",
       "         [-1.7919e+02, -1.9096e+02, -2.0855e+02,  ..., -1.8622e+02,\n",
       "          -1.9051e+02, -1.8739e+02]],\n",
       "\n",
       "        [[ 2.5203e+02,  2.5763e+02,  2.7174e+02,  ...,  2.6204e+02,\n",
       "           2.5965e+02,  2.7133e+02],\n",
       "         [ 1.7768e+02,  2.0171e+02,  2.0152e+02,  ...,  2.0342e+02,\n",
       "           1.9015e+02,  1.9199e+02],\n",
       "         [ 3.2484e+02,  3.3740e+02,  3.5419e+02,  ...,  3.4510e+02,\n",
       "           3.3304e+02,  3.3961e+02],\n",
       "         ...,\n",
       "         [ 1.9260e+02,  2.0005e+02,  2.2089e+02,  ...,  2.0626e+02,\n",
       "           1.9634e+02,  2.1100e+02],\n",
       "         [ 2.4112e+02,  2.5114e+02,  2.6718e+02,  ...,  2.6188e+02,\n",
       "           2.5506e+02,  2.7013e+02],\n",
       "         [ 2.0727e+02,  2.1408e+02,  2.3427e+02,  ...,  2.2524e+02,\n",
       "           2.1815e+02,  2.2094e+02]],\n",
       "\n",
       "        [[-5.2970e+01, -5.4476e+01, -7.3467e+01,  ..., -6.6846e+01,\n",
       "          -6.5084e+01, -6.5620e+01],\n",
       "         [-5.8602e+01, -6.1401e+01, -8.6376e+01,  ..., -7.3516e+01,\n",
       "          -6.7953e+01, -8.1301e+01],\n",
       "         [-8.9407e+01, -8.4512e+01, -1.1433e+02,  ..., -1.0107e+02,\n",
       "          -1.0126e+02, -1.0244e+02],\n",
       "         ...,\n",
       "         [-6.7578e+01, -6.2773e+01, -9.0397e+01,  ..., -8.6343e+01,\n",
       "          -8.4078e+01, -8.0945e+01],\n",
       "         [-1.0436e+01, -1.0283e+01, -3.5069e+01,  ..., -2.7295e+01,\n",
       "          -1.8633e+01, -2.9515e+01],\n",
       "         [-5.0656e+01, -5.0123e+01, -7.3576e+01,  ..., -6.1087e+01,\n",
       "          -6.0355e+01, -6.1912e+01]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ce4288d-6909-48a3-ab2d-59732bf3108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.6623e+01,  1.0004e+02,  8.5799e+01,  ...,  8.7449e+01,\n",
       "           9.1846e+01,  7.8039e+01],\n",
       "         [ 8.8996e+01,  1.0819e+02,  9.4816e+01,  ...,  8.4765e+01,\n",
       "           9.4907e+01,  7.5187e+01],\n",
       "         [ 3.7771e+01,  5.9991e+01,  3.8072e+01,  ...,  3.0049e+01,\n",
       "           4.2725e+01,  3.2111e+01],\n",
       "         ...,\n",
       "         [ 7.2630e+01,  8.7932e+01,  6.9825e+01,  ...,  6.4968e+01,\n",
       "           7.2998e+01,  6.3225e+01],\n",
       "         [ 1.4554e+01,  3.9056e+01,  2.0167e+01,  ...,  1.6744e-01,\n",
       "           2.0827e+01,  1.2686e+01],\n",
       "         [ 7.2106e+01,  8.9304e+01,  7.1058e+01,  ...,  6.4948e+01,\n",
       "           9.0308e+01,  5.9325e+01]],\n",
       "\n",
       "        [[ 6.7270e+01,  8.0736e+01,  9.4496e+01,  ...,  7.3723e+01,\n",
       "           7.8385e+01,  9.5040e+01],\n",
       "         [ 4.2410e+01,  5.2445e+01,  5.8947e+01,  ...,  3.9207e+01,\n",
       "           4.4767e+01,  6.2313e+01],\n",
       "         [ 2.5079e+01,  3.2240e+01,  3.6893e+01,  ...,  1.4306e+01,\n",
       "           2.8351e+01,  4.3981e+01],\n",
       "         ...,\n",
       "         [ 2.0622e+01,  2.8156e+01,  3.3530e+01,  ...,  8.4376e+00,\n",
       "           2.1194e+01,  3.3177e+01],\n",
       "         [ 1.9105e+01,  2.2766e+01,  3.1752e+01,  ...,  9.7092e+00,\n",
       "           1.8238e+01,  3.8131e+01],\n",
       "         [ 5.5310e+01,  6.3663e+01,  8.3023e+01,  ...,  5.0452e+01,\n",
       "           7.0358e+01,  8.3967e+01]],\n",
       "\n",
       "        [[-9.2828e+01, -8.9145e+01, -9.3193e+01,  ..., -8.0004e+01,\n",
       "          -8.4481e+01, -7.4275e+01],\n",
       "         [-8.5125e+00, -8.5246e+00, -2.1452e+01,  ...,  4.2066e+00,\n",
       "          -8.8903e+00,  1.0014e+00],\n",
       "         [-1.4441e+02, -1.3510e+02, -1.5305e+02,  ..., -1.2592e+02,\n",
       "          -1.4474e+02, -1.3103e+02],\n",
       "         ...,\n",
       "         [-2.5822e+01, -2.5320e+01, -3.1544e+01,  ..., -3.3275e+00,\n",
       "          -2.2886e+01, -1.4478e+01],\n",
       "         [-8.3255e+01, -7.5705e+01, -8.9342e+01,  ..., -6.2693e+01,\n",
       "          -8.0315e+01, -6.9163e+01],\n",
       "         [-9.2838e+01, -8.6358e+01, -9.4982e+01,  ..., -7.3364e+01,\n",
       "          -8.4196e+01, -7.7699e+01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.3326e+02, -2.3048e+02, -2.6053e+02,  ..., -2.3539e+02,\n",
       "          -2.3759e+02, -2.4009e+02],\n",
       "         [-1.6389e+02, -1.6570e+02, -1.8833e+02,  ..., -1.7097e+02,\n",
       "          -1.7373e+02, -1.7032e+02],\n",
       "         [-2.0599e+02, -2.1023e+02, -2.3443e+02,  ..., -2.0950e+02,\n",
       "          -2.1448e+02, -2.1053e+02],\n",
       "         ...,\n",
       "         [-1.7779e+02, -1.8613e+02, -2.0645e+02,  ..., -1.8145e+02,\n",
       "          -1.8151e+02, -1.8942e+02],\n",
       "         [-1.7774e+02, -1.7523e+02, -2.0815e+02,  ..., -1.8391e+02,\n",
       "          -1.8145e+02, -1.8661e+02],\n",
       "         [-1.7919e+02, -1.9096e+02, -2.0855e+02,  ..., -1.8622e+02,\n",
       "          -1.9050e+02, -1.8739e+02]],\n",
       "\n",
       "        [[ 2.5203e+02,  2.5762e+02,  2.7174e+02,  ...,  2.6204e+02,\n",
       "           2.5965e+02,  2.7133e+02],\n",
       "         [ 1.7768e+02,  2.0171e+02,  2.0152e+02,  ...,  2.0342e+02,\n",
       "           1.9015e+02,  1.9199e+02],\n",
       "         [ 3.2484e+02,  3.3740e+02,  3.5419e+02,  ...,  3.4510e+02,\n",
       "           3.3304e+02,  3.3961e+02],\n",
       "         ...,\n",
       "         [ 1.9260e+02,  2.0005e+02,  2.2089e+02,  ...,  2.0626e+02,\n",
       "           1.9634e+02,  2.1100e+02],\n",
       "         [ 2.4112e+02,  2.5114e+02,  2.6718e+02,  ...,  2.6188e+02,\n",
       "           2.5506e+02,  2.7012e+02],\n",
       "         [ 2.0727e+02,  2.1408e+02,  2.3427e+02,  ...,  2.2524e+02,\n",
       "           2.1815e+02,  2.2094e+02]],\n",
       "\n",
       "        [[-5.2968e+01, -5.4475e+01, -7.3465e+01,  ..., -6.6845e+01,\n",
       "          -6.5083e+01, -6.5618e+01],\n",
       "         [-5.8601e+01, -6.1400e+01, -8.6375e+01,  ..., -7.3514e+01,\n",
       "          -6.7952e+01, -8.1300e+01],\n",
       "         [-8.9406e+01, -8.4511e+01, -1.1433e+02,  ..., -1.0107e+02,\n",
       "          -1.0126e+02, -1.0243e+02],\n",
       "         ...,\n",
       "         [-6.7576e+01, -6.2772e+01, -9.0396e+01,  ..., -8.6342e+01,\n",
       "          -8.4077e+01, -8.0944e+01],\n",
       "         [-1.0434e+01, -1.0282e+01, -3.5068e+01,  ..., -2.7293e+01,\n",
       "          -1.8632e+01, -2.9514e+01],\n",
       "         [-5.0654e+01, -5.0121e+01, -7.3575e+01,  ..., -6.1086e+01,\n",
       "          -6.0354e+01, -6.1910e+01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9634ffe0-438a-49c8-9852-0c444d37d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(res1, res2, atol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6e81720-a99a-4333-919f-4e0d2a231901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
